# Web 入门: 建立你的第一个网站

## 1、[文件处理](https://developer.mozilla.org/zh-CN/docs/Learn/Getting_started_with_the_web/Dealing_with_files)

一个网站由文本、代码、样式表、媒体内容等等的各种文件组成。当你开发网站时，你需要以清晰的结构将它们存储在你的本地计算机中，保证这些文件之间的联系，使它们看起来正确，然后才能将它们[上传至服务器](https://developer.mozilla.org/zh-CN/Learn/Getting_started_with_the_web/Publishing_your_website)。

![1566124938884](C:\Users\baideqian\AppData\Roaming\Typora\typora-user-images\1566124938884.png)



## 2、[HTML 基础](https://developer.mozilla.org/zh-CN/docs/Learn/Getting_started_with_the_web/HTML_basics)

超文本标记语言 (英语：**H**yper**t**ext **M**arkup **L**anguage，简称：HTML ) 是一种用来结构化 Web 网页及其内容的标记语言。网页内容可以是：一组段落、一个重点信息列表、也可以含有图片和数据表。

![HTML åç´ ](https://mdn.mozillademos.org/files/16475/element.png)



## 3、[CSS 基础](https://developer.mozilla.org/zh-CN/docs/Learn/Getting_started_with_the_web/CSS_basics)

层叠样式表（**C**ascading **S**tyle **S**heet，简称：CSS）是为网页添加样式的代码。 CSS 可以解决如下问题：怎样将文本设置为黑色或红色？怎样将内容显示在屏幕的特定位置？怎样用背景图片或颜色来装饰网页？



## 4、[JavaScript基础](https://developer.mozilla.org/zh-CN/docs/Learn/Getting_started_with_the_web/JavaScript_basics)

JavaScript 是一门编程语言，可为网站添加交互功能。（例如：游戏、动态样式，动画，以及在按下按钮或收到表单数据时做出的响应，等）。



# 新闻人物言论自动提取

## 1. 数据库部分



## 2. 算法模型部分

### 1.  使用wiki中文语料和新闻语料训练word2vector

- 使用维基百科下载中文语料库
- 从下载的语料库中抽取维基百科的内容，将其保存在txt文件中
- 维基百科中的内容有的是繁体字，需要将其转换成简体字，推荐使用[hanziconv](https://pypi.org/project/hanziconv/)一行代码搞定
- 使用jieba进行切词，然后存进新的文件中
- 用Gensim的`LineSentenc`类读取含有切分好的单词的txt文件，训练成词向量Model

### 2. 使用词向量模型获取“说”的近义词

### 3. 判断句子结束

#### 3.1 基于SIF方法计算句子相似度，来判断句子结束

要确定言论的结束，最简单的方式是碰见句号的时候就停止，但是有的言论可能是跨了多个句号，那么此时如何确定言论的结束，就是一个比较 tricky 的问题。 解决方法是：**把判断两句话是不是类似的、是不是说的同一个主题这个问题变成这两个句子的距离是不是小于某个阈值，方法就是使用向量进行对比** 

- 要获得句子的向量，一种方法是使用 Tf-idf  进行句子向量化。 Tf-idf 这是一种比较基础的向量化方式， 但是不能判断不相同的单词的语义相似性。

在词向量提出来之后，有一个比较好的方式就是基于词向量进行句子的向量化，普林斯顿在2017 年提出来一个方法：SIF，原理是使用单词的词向量加权 + PCA 降维  

- 作为一种**无监督**计算句子之间相似度的方法, **sif sentence embedding**使用预训练好的词向量, 使用加权平均的方法, 对句子中所有词对应的词向量进行计算, 得到整个句子的embedding向量. 再使用句子向量进行相似度的计算

​       基本思路是：给定上下文中，一个词的出现概率由上下文和作为平滑项的词频决定, 算法内容如下：

​       **输入**： 
​       预训练的词向量 ${v_w:w∈V}$，例如`word2vec、glove`等 

​       待处理的句子集合 $S$

​       参数$a$（论文中建议$a$的范围：$[1e−4,1e−3]$）

​       词频估计 ${p(w):w∈V}$

​       **输出**： 
​       句子向量${v_s:s∈S}$

​       算法的关键两步如下

​     ![1567387204871](F:\ML\Deep Learning\NLP\Course\2019-summer\p1\1567387204871.png) 

-  第一步：计算向量表示的平均值，每个单词都有一个独立的权重，权重为常数α除以α与单词频率的和。    这样的话可以使高频词的权重较小。 

-  第二步：针对所有句子组成的句子表示矩阵，计算每个句子表示的第一主成分，然后减去在第一主成分上的投影。 类似PCA：使用sklearn中的`TruncatedSVD`计算每个句子表示的第一主成分

参考：

1. https://www.cnblogs.com/databingo/p/9788244.html
2. https://blog.csdn.net/sinat_31188625/article/details/72677088#commentsedit
3. https://blog.csdn.net/yxiachan/article/details/81292902
4. https://github.com/PrincetonML/SIF

#### 3.2 基于rnn判断一句话能否作为人说的话，来判断句子结束

使用双向循环神经网络模型，在这个模型中，

- 首先，每个词通过嵌入层得到**特征向量**。
- 然后，使用双向循环神经网络对特征序列进一步编码得到**序列信息**。
- 最后，将编码的序列信息通过**全连接层**变换为输出。具体来说，
    - 我们可以将双向长短期记忆在最初时间步和最终时间步的隐藏状态连结，
    - 作为特征序列的表征传递给输出层分类。
- 在实现的`BiRNN`类中，
    - `Embedding`实例即嵌入层
    - `LSTM`实例即为序列编码的隐藏层
    - `Dense`实例即生成分类结果的输出层。

#### 3.3 综合句子相似度和rnn模型判断

- rnn判断结果为True则直接返回
- rnn判断结果为False且可信度大于阈值则返回False
- rnn判断结果为False且可信度小于阈值则根据相似度判断

#### 3.4 算法模型部分用到的Python编程技术

1. [类的继承](file:///F:/Python/Pyhton%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/190603-11%20_%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E4%BB%8E%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E7%B1%BB%E6%AF%94%E8%AF%B4%E8%B5%B7.html)
2. [高阶函数和可调用对象上的操作](https://docs.python.org/zh-cn/3/library/functools.html) 

## 3. Web 前端展示部分

使用 HTML，Python Web 服务进行网页展示

技术栈：Flask+ Bootstrap + HTML（+D3）

## 4. 从另一个角度理解这个项目

在输入框中输入待提取文本，点击**提取**之后依次发生： 

1. 分句
2. 句子依存分析
   - 构建依存树
   - 查找说话的实体和内容
     - 查找说话实体：状中结构查找实体
     - 获取实体说的话
3. 根据句子相似度进行判断
4. 低于某个阈值则判定为结束